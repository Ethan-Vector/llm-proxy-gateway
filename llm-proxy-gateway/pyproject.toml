[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm-proxy-gateway"
version = "0.1.0"
description = "OpenAI-compatible LLM proxy gateway with routing, auth, rate limiting, and eval harness."
readme = "README.md"
requires-python = ">=3.10"
license = { text = "MIT" }
authors = [{ name = "Ethan (pen name)", email = "noreply@example.com" }]
dependencies = [
  "fastapi>=0.110",
  "uvicorn[standard]>=0.27",
  "pydantic>=2.6",
  "pydantic-settings>=2.2",
  "pyyaml>=6.0",
  "httpx>=0.26",
]

[project.optional-dependencies]
dev = [
  "pytest>=7.4",
  "pytest-asyncio>=0.23",
  "ruff>=0.5",
  "types-PyYAML",
]

[project.scripts]
llm-proxy = "llm_proxy_gateway.cli:main"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP"]
ignore = ["E501"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
